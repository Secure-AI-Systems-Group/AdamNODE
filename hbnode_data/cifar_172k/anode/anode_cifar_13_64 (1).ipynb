{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "anode_cifar_13_64.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "449562f5c1844ac08d15912e7fb79b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9839bdb922714caf8fe2ac2542371392",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aca98e40b2f94527a86661597ac01ed1",
              "IPY_MODEL_7edbd14d446b491eb68f05e502a522ab"
            ]
          }
        },
        "9839bdb922714caf8fe2ac2542371392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aca98e40b2f94527a86661597ac01ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a7f751a964c45b1b5414c1e28e1f999",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6e0dc97a93f4db2b42fb61c6d240521"
          }
        },
        "7edbd14d446b491eb68f05e502a522ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7486eb490dc144e199f38612fc1ebcd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:20&lt;00:00, 54972711.85it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aa8bc64365445dcb80558f6c8ba1098"
          }
        },
        "5a7f751a964c45b1b5414c1e28e1f999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6e0dc97a93f4db2b42fb61c6d240521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7486eb490dc144e199f38612fc1ebcd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aa8bc64365445dcb80558f6c8ba1098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo7Nzsct_J1b"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90xQE3Fyd46H",
        "outputId": "cc516daf-3f2c-4ba8-e1ae-9d3352514e5e"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 12873304705088487595, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14638920512\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 8589819103854549468\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AakLvzk_MLL"
      },
      "source": [
        "# misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYebnHN2Mqng",
        "outputId": "05e9dd61-20dd-401f-ec03-a8dbe2cea2a0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torchdiffeq\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "import numpy as np\n",
        "!pip install einops\n",
        "from einops import rearrange, repeat\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import glob\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "from math import pi\n",
        "from random import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import Normal\n",
        "from torchvision import datasets, transforms\n",
        "tol = 1e-3\n",
        "gpu = 0\n",
        "niters = 10\n",
        "lr = 1e-3\n",
        "# Format [time, batch, diff, vector]\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class ArgumentParser:\n",
        "    def add_argument(self, str, type, default):\n",
        "        setattr(self, str[2:], default)\n",
        "\n",
        "    def parse_args(self):\n",
        "        return self\n",
        "\n",
        "def str_rec (names, data, unit=None, sep=', ', presets='{}'):\n",
        "    if unit is None:\n",
        "        unit = [''] * len(names)\n",
        "    data = [str(i)[:6] for i in data]\n",
        "    out_str = \"{}: {{}} {{{{}}}}\" + sep\n",
        "    out_str *= len(names)\n",
        "    out_str = out_str.format(*names)\n",
        "    out_str = out_str.format(*data)\n",
        "    out_str = out_str.format(*unit)\n",
        "    out_str = presets.format(out_str)\n",
        "    return out_str\n",
        "\n",
        "rec_names = [\"iter\", \"loss\", \"nfe\", \"time/iter\", \"time\"]\n",
        "rec_unit = [\"\",\"\",\"\",\"s\",\"min\"]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchdiffeq\n",
            "  Downloading https://files.pythonhosted.org/packages/90/e4/5e483dc28a0a520e403f4dade7ad120d739471693afe83eaf36c9cc09cb0/torchdiffeq-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq) (1.7.0+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->torchdiffeq) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->torchdiffeq) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->torchdiffeq) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->torchdiffeq) (1.19.5)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.0\n",
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SI8itCE_Nwb"
      },
      "source": [
        "# base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJvesZWWMqqg"
      },
      "source": [
        "\n",
        "\n",
        "class Example_df(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, nhid=20):\n",
        "        super(Example_df, self).__init__()\n",
        "        self.dense1 = nn.Linear(input_dim, nhid)\n",
        "        self.dense2 = nn.Linear(nhid, output_dim)\n",
        "        self.lrelu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        x = self.dense1(x)\n",
        "        x = self.lrelu(x)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class NODEintegrate(nn.Module):\n",
        "\n",
        "    def __init__(self, df=None, x0=None):\n",
        "        \"\"\"\n",
        "        Create an OdeRnnBase model\n",
        "            x' = df(x)\n",
        "            x(t0) = x0\n",
        "        :param df: a function that computes derivative. input & output shape [batch, channel, feature]\n",
        "        :param x0: initial condition.\n",
        "            - if x0 is set to be nn.parameter then it can be trained.\n",
        "            - if x0 is set to be nn.Module then it can be computed through some network.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.x0 = x0\n",
        "\n",
        "    def forward(self, initial_condition, evaluation_times, x0stats=None):\n",
        "        \"\"\"\n",
        "        Evaluate odefunc at given evaluation time\n",
        "        :param initial_condition: shape [batch, channel, feature]. Set to None while training.\n",
        "        :param evaluation_times: time stamps where method evaluates, shape [time]\n",
        "        :param x0stats: statistics to compute x0 when self.x0 is a nn.Module, shape required by self.x0\n",
        "        :return: prediction by ode at evaluation_times, shape [time, batch, channel, feature]\n",
        "        \"\"\"\n",
        "        if initial_condition is None:\n",
        "            initial_condition = self.x0\n",
        "        if x0stats is not None:\n",
        "            initial_condition = self.x0(x0stats)\n",
        "        out = odeint(self.df, initial_condition, evaluation_times, rtol=tol, atol=tol)\n",
        "        return out\n",
        "\n",
        "    @property\n",
        "    def nfe(self):\n",
        "        return self.df.nfe\n",
        "\n",
        "\n",
        "class NODElayer(nn.Module):\n",
        "    def __init__(self, df, evaluation_times=(0.0, 1.0)):\n",
        "        super(NODElayer, self).__init__()\n",
        "        self.df = df\n",
        "        self.evaluation_times = torch.as_tensor(evaluation_times)\n",
        "\n",
        "    def forward(self, x0):\n",
        "        out = odeint(self.df, x0, self.evaluation_times, rtol=tol, atol=tol)\n",
        "        return out[1]\n",
        "\n",
        "    def to(self, device, *args, **kwargs):\n",
        "        super().to(device, *args, **kwargs)\n",
        "        self.evaluation_times.to(device)\n",
        "\n",
        "\n",
        "class NODE(nn.Module):\n",
        "    def __init__(self, df=None, **kwargs):\n",
        "        super(NODE, self).__init__()\n",
        "        self.__dict__.update(kwargs)\n",
        "        self.df = df\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        self.nfe += 1\n",
        "        return self.df(t, x)\n",
        "\n",
        "\n",
        "class SONODE(NODE):\n",
        "    def forward(self, t, x):\n",
        "        \"\"\"\n",
        "        Compute [y y']' = [y' y''] = [y' df(t, y, y')]\n",
        "        :param t: time, shape [1]\n",
        "        :param x: [y y'], shape [batch, 2, vec]\n",
        "        :return: [y y']', shape [batch, 2, vec]\n",
        "        \"\"\"\n",
        "        self.nfe += 1\n",
        "        v = x[:, 1:, :]\n",
        "        out = self.df(t, x)\n",
        "        return torch.cat((v, out), dim=1)\n",
        "\n",
        "\n",
        "class HeavyBallODE(NODE):\n",
        "    def __init__(self, df, gamma=None):\n",
        "        super().__init__(df)\n",
        "        if gamma is None:\n",
        "            self.gamma = nn.Parameter(torch.Tensor([-4.0]))\n",
        "        else:\n",
        "            self.gamma = gamma\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        \"\"\"\n",
        "        Compute [theta' m' v'] with heavy ball parametrization in\n",
        "        $$ theta' = -m / sqrt(v + eps) $$\n",
        "        $$ m' = h f'(theta) - rm $$\n",
        "        $$ v' = p (f'(theta))^2 - qv $$\n",
        "        https://www.jmlr.org/papers/volume21/18-808/18-808.pdf\n",
        "        because v is constant, we change c -> 1/sqrt(v)\n",
        "        c has to be positive\n",
        "        :param t: time, shape [1]\n",
        "        :param x: [theta m v], shape [batch, 3, dim]\n",
        "        :return: [theta' m' v'], shape [batch, 3, dim]\n",
        "        \"\"\"\n",
        "        self.nfe += 1\n",
        "        theta, m = torch.split(x, 1, dim=1)\n",
        "        dtheta = - m\n",
        "        dm = self.df(t, theta) - torch.sigmoid(self.gamma) * m\n",
        "        return torch.cat((dtheta, dm), dim=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa60COrh_PXj"
      },
      "source": [
        "# train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb2XnA0z_CsE"
      },
      "source": [
        "def train(model, optimizer, trdat, tsdat):\n",
        "    epoch = 0\n",
        "    itrcnt = 0\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    itr_arr = np.zeros(args.niters)\n",
        "    loss_arr = np.zeros(args.niters)\n",
        "    nfe_arr = np.zeros(args.niters)\n",
        "    time_arr = np.zeros(args.niters)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.95)\n",
        "\n",
        "    # training\n",
        "    start_time = time.time()\n",
        "    while epoch < args.niters:\n",
        "        epoch += 1\n",
        "        iter_start_time = time.time()\n",
        "        for x, y in trdat:\n",
        "            itrcnt += 1\n",
        "            model[1].df.nfe = 0\n",
        "            optimizer.zero_grad()\n",
        "            # forward in time and solve ode\n",
        "            pred_y = model(x.to(device=args.gpu))\n",
        "            # compute loss\n",
        "            loss = loss_func(pred_y, y.to(device=args.gpu))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            # make arrays\n",
        "            itr_arr[epoch - 1] = epoch\n",
        "            loss_arr[epoch - 1] += loss.detach()\n",
        "            nfe_arr[epoch - 1] += model[1].df.nfe\n",
        "        iter_end_time = time.time()\n",
        "        time_arr[epoch - 1] = iter_end_time - iter_start_time\n",
        "        loss_arr[epoch - 1] *= 1.0 * epoch / itrcnt\n",
        "        nfe_arr[epoch - 1] *= 1.0 * epoch / itrcnt\n",
        "        printouts = [epoch, loss_arr[epoch-1], nfe_arr[epoch-1], time_arr[epoch-1], (time.time()-start_time)/60]\n",
        "        print(str_rec(rec_names, printouts, rec_unit, presets=\"Train|| {}\"))\n",
        "        if epoch % 2 == 0:\n",
        "            model[1].df.nfe = 0\n",
        "            end_time = time.time()\n",
        "            loss = 0\n",
        "            acc = 0\n",
        "            dsize = 0\n",
        "            bcnt = 0\n",
        "            for x, y in tsdat:\n",
        "                # forward in time and solve ode\n",
        "                dsize += y.shape[0]\n",
        "                y = y.to(device=args.gpu)\n",
        "                pred_y = model(x.to(device=args.gpu))\n",
        "                pred_l = torch.argmax(pred_y, dim=1)\n",
        "                acc += torch.sum((pred_l == y).float())\n",
        "                bcnt += 1\n",
        "                # compute loss\n",
        "                loss += loss_func(pred_y, y).detach() * y.shape[0]\n",
        "\n",
        "            loss /= dsize\n",
        "            acc /= dsize\n",
        "            printouts = [epoch, loss.detach().cpu().numpy(), acc.detach().cpu().numpy(), str(model[1].df.nfe / bcnt), str(count_parameters(model))]\n",
        "            names = [\"iter\", \"loss\", \"acc\", \"nfe\", \"param cnt\"]\n",
        "            print(str_rec(names, printouts, presets=\"Test || {}\"))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ89SupJASlM"
      },
      "source": [
        "# anode_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRSvXX3RAUYb"
      },
      "source": [
        "def cifar(batch_size=64, size=32, path_to_data='../cifar_data'):\n",
        "    \"\"\"CIFAR dataloader with (3, 32, 32) images.\n",
        "    Parameters\n",
        "    ----------\n",
        "    batch_size : int\n",
        "    size : int\n",
        "        Size (height and width) of each image. Default is 28 for no resizing.\n",
        "    path_to_data : string\n",
        "        Path to CIFAR data files.\n",
        "    \"\"\"\n",
        "    all_transforms = transforms.Compose([\n",
        "        transforms.Resize(size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    train_data = datasets.CIFAR10(path_to_data, train=True, download=True,\n",
        "                                transform=all_transforms)\n",
        "    test_data = datasets.CIFAR10(path_to_data, train=False,\n",
        "                               transform=all_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em6DdhJS_QzU"
      },
      "source": [
        "# anode_cifar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "449562f5c1844ac08d15912e7fb79b66",
            "9839bdb922714caf8fe2ac2542371392",
            "aca98e40b2f94527a86661597ac01ed1",
            "7edbd14d446b491eb68f05e502a522ab",
            "5a7f751a964c45b1b5414c1e28e1f999",
            "e6e0dc97a93f4db2b42fb61c6d240521",
            "7486eb490dc144e199f38612fc1ebcd3",
            "4aa8bc64365445dcb80558f6c8ba1098"
          ]
        },
        "id": "zgmrJn6XMq-4",
        "outputId": "50f85f5d-01ee-4f59-ef6b-b965d362fc23"
      },
      "source": [
        "parser = ArgumentParser()\n",
        "parser.add_argument('--tol', type=float, default=1e-3)\n",
        "parser.add_argument('--adjoint', type=eval, default=False)\n",
        "parser.add_argument('--visualize', type=eval, default=True)\n",
        "parser.add_argument('--niters', type=int, default=40)\n",
        "parser.add_argument('--lr', type=float, default=0.001)\n",
        "parser.add_argument('--gpu', type=int, default=0)\n",
        "args = parser.parse_args()\n",
        "\n",
        "# shape: [time, batch, derivatives, channel, x, y]\n",
        "trdat, tsdat = cifar(batch_size=256)\n",
        "\n",
        "\n",
        "class anode_initial_velocity(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, aug):\n",
        "        super(anode_initial_velocity, self).__init__()\n",
        "        self.aug = aug\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x0 = rearrange(x0.float(), 'b c x y -> b 1 c x y')\n",
        "        outshape = list(x0.shape)\n",
        "        outshape[2] = self.aug\n",
        "        out = torch.zeros(outshape).to(args.gpu)\n",
        "        out[:, :, :3] += x0\n",
        "        return out\n",
        "\n",
        "\n",
        "class DF(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, nhid, out_channels=None):\n",
        "        super(DF, self).__init__()\n",
        "        if out_channels is None:\n",
        "            out_channels = in_channels\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.fc1 = nn.Conv2d(in_channels + 1, nhid, kernel_size=1, padding=0)\n",
        "        self.fc2 = nn.Conv2d(nhid + 1, nhid, kernel_size=3, padding=1)\n",
        "        self.fc3 = nn.Conv2d(nhid + 1, out_channels, kernel_size=1, padding=0)\n",
        "\n",
        "    def forward(self, t, x0):\n",
        "        x0 = rearrange(x0, 'b d c x y -> b (d c) x y')\n",
        "        t_img = torch.ones_like(x0[:, :1, :, :]).to(device=args.gpu) * t\n",
        "        out = torch.cat([x0, t_img], dim=1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.activation(out)\n",
        "        out = torch.cat([out, t_img], dim=1)\n",
        "        out = self.fc2(out)\n",
        "        out = self.activation(out)\n",
        "        out = torch.cat([out, t_img], dim=1)\n",
        "        out = self.fc3(out)\n",
        "        out = rearrange(out, 'b c x y -> b 1 c x y')\n",
        "        return out\n",
        "\n",
        "class predictionlayer(nn.Module):\n",
        "    def __init__(self, in_channels, truncate=False):\n",
        "        super(predictionlayer, self).__init__()\n",
        "        self.dense = nn.Linear(in_channels * 32 * 32, 10)\n",
        "        self.truncate = truncate\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.truncate:\n",
        "            x = rearrange(x[:,0], 'b ... -> b (...)')\n",
        "        else:\n",
        "            x = rearrange(x, 'b ... -> b (...)')\n",
        "        x = self.dense(x)\n",
        "        return x\n",
        "\n",
        "dim = 13\n",
        "nhid = 64\n",
        "layer = NODElayer(NODE(DF(dim, nhid)))\n",
        "model = nn.Sequential(anode_initial_velocity(3, dim), layer, predictionlayer(dim)).to(device=args.gpu)\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.00)\n",
        "print(count_parameters(model))\n",
        "train(model, optimizer, trdat, tsdat)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar_data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "449562f5c1844ac08d15912e7fb79b66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../cifar_data/cifar-10-python.tar.gz to ../cifar_data\n",
            "172452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchdiffeq/_impl/misc.py:298: UserWarning: t is not on the same device as y0. Coercing to y0.device.\n",
            "  warnings.warn(\"t is not on the same device as y0. Coercing to y0.device.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train|| iter: 1 , loss: 1.7850 , nfe: 40.244 , time/iter: 259.20 s, time: 4.3200 min, \n",
            "Train|| iter: 2 , loss: 1.5362 , nfe: 41.653 , time/iter: 272.70 s, time: 8.8651 min, \n",
            "Test || iter: 2 , loss: 1.5090 , acc: 0.4669 , nfe: 20.0 , param cnt: 172452 , \n",
            "Train|| iter: 3 , loss: 1.4264 , nfe: 45.999 , time/iter: 316.10 s, time: 14.326 min, \n",
            "Train|| iter: 4 , loss: 1.3294 , nfe: 46.642 , time/iter: 322.72 s, time: 19.705 min, \n",
            "Test || iter: 4 , loss: 1.3508 , acc: 0.5173 , nfe: 20.0 , param cnt: 172452 , \n",
            "Train|| iter: 5 , loss: 1.2471 , nfe: 47.316 , time/iter: 329.67 s, time: 25.393 min, \n",
            "Train|| iter: 6 , loss: 1.1437 , nfe: 47.102 , time/iter: 327.98 s, time: 30.860 min, \n",
            "Test || iter: 6 , loss: 1.2091 , acc: 0.5712 , nfe: 20.0 , param cnt: 172452 , \n",
            "Train|| iter: 7 , loss: 1.0713 , nfe: 47.499 , time/iter: 331.64 s, time: 36.580 min, \n",
            "Train|| iter: 8 , loss: 1.0072 , nfe: 50.346 , time/iter: 360.10 s, time: 42.581 min, \n",
            "Test || iter: 8 , loss: 1.1581 , acc: 0.5931 , nfe: 20.0 , param cnt: 172452 , \n",
            "Train|| iter: 9 , loss: 0.9506 , nfe: 53.561 , time/iter: 390.72 s, time: 49.285 min, \n",
            "Train|| iter: 10 , loss: 0.8934 , nfe: 56.469 , time/iter: 419.39 s, time: 56.275 min, \n",
            "Test || iter: 10 , loss: 1.1687 , acc: 0.5988 , nfe: 20.0 , param cnt: 172452 , \n",
            "Train|| iter: 11 , loss: 0.8294 , nfe: 60.448 , time/iter: 447.11 s, time: 63.920 min, \n",
            "Train|| iter: 12 , loss: 0.7680 , nfe: 67.489 , time/iter: 484.59 s, time: 71.996 min, \n",
            "Test || iter: 12 , loss: 1.1654 , acc: 0.6035 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 13 , loss: 0.7040 , nfe: 68.989 , time/iter: 499.41 s, time: 80.566 min, \n",
            "Train|| iter: 14 , loss: 0.6446 , nfe: 70.857 , time/iter: 516.80 s, time: 89.179 min, \n",
            "Test || iter: 14 , loss: 1.2064 , acc: 0.6091 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 15 , loss: 0.5812 , nfe: 71.653 , time/iter: 524.46 s, time: 98.165 min, \n",
            "Train|| iter: 16 , loss: 0.5216 , nfe: 73.887 , time/iter: 546.90 s, time: 107.28 min, \n",
            "Test || iter: 16 , loss: 1.2992 , acc: 0.6060 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 17 , loss: 0.4657 , nfe: 74.653 , time/iter: 554.53 s, time: 116.76 min, \n",
            "Train|| iter: 18 , loss: 0.4138 , nfe: 76.704 , time/iter: 574.17 s, time: 126.33 min, \n",
            "Test || iter: 18 , loss: 1.5028 , acc: 0.5948 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 19 , loss: 0.3728 , nfe: 79.795 , time/iter: 603.86 s, time: 136.64 min, \n",
            "Train|| iter: 20 , loss: 0.3294 , nfe: 82.918 , time/iter: 634.20 s, time: 147.21 min, \n",
            "Test || iter: 20 , loss: 1.7270 , acc: 0.5959 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 21 , loss: 0.2849 , nfe: 82.979 , time/iter: 635.72 s, time: 158.05 min, \n",
            "Train|| iter: 22 , loss: 0.2375 , nfe: 84.540 , time/iter: 650.32 s, time: 168.89 min, \n",
            "Test || iter: 22 , loss: 2.1599 , acc: 0.5902 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 23 , loss: 0.2032 , nfe: 86.744 , time/iter: 672.43 s, time: 180.35 min, \n",
            "Train|| iter: 24 , loss: 0.1723 , nfe: 87.816 , time/iter: 682.95 s, time: 191.73 min, \n",
            "Test || iter: 24 , loss: 2.6579 , acc: 0.5823 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 25 , loss: 0.1451 , nfe: 88.704 , time/iter: 690.90 s, time: 203.49 min, \n",
            "Train|| iter: 26 , loss: 0.1211 , nfe: 90.265 , time/iter: 706.04 s, time: 215.26 min, \n",
            "Test || iter: 26 , loss: 3.0317 , acc: 0.5798 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 27 , loss: 0.0991 , nfe: 88.979 , time/iter: 694.11 s, time: 227.07 min, \n",
            "Train|| iter: 28 , loss: 0.0861 , nfe: 89.530 , time/iter: 699.45 s, time: 238.73 min, \n",
            "Test || iter: 28 , loss: 3.6182 , acc: 0.5739 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 29 , loss: 0.0771 , nfe: 90.112 , time/iter: 705.23 s, time: 250.73 min, \n",
            "Train|| iter: 30 , loss: 0.0696 , nfe: 90.602 , time/iter: 709.85 s, time: 262.56 min, \n",
            "Test || iter: 30 , loss: 3.8988 , acc: 0.5740 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 31 , loss: 0.0619 , nfe: 90.387 , time/iter: 707.36 s, time: 274.59 min, \n",
            "Train|| iter: 32 , loss: 0.0548 , nfe: 90.479 , time/iter: 707.86 s, time: 286.39 min, \n",
            "Test || iter: 32 , loss: 4.3028 , acc: 0.5718 , nfe: 26.0 , param cnt: 172452 , \n",
            "Train|| iter: 33 , loss: 0.0531 , nfe: 92.132 , time/iter: 721.36 s, time: 298.66 min, \n",
            "Train|| iter: 34 , loss: 0.0513 , nfe: 92.744 , time/iter: 721.79 s, time: 310.69 min, \n",
            "Test || iter: 34 , loss: 4.6576 , acc: 0.57 , nfe: 28.4 , param cnt: 172452 , \n",
            "Train|| iter: 35 , loss: 0.0435 , nfe: 95.163 , time/iter: 725.99 s, time: 323.05 min, \n",
            "Train|| iter: 36 , loss: 0.0422 , nfe: 94.520 , time/iter: 717.53 s, time: 335.01 min, \n",
            "Test || iter: 36 , loss: 4.8654 , acc: 0.5701 , nfe: 27.35 , param cnt: 172452 , \n",
            "Train|| iter: 37 , loss: 0.0380 , nfe: 94.857 , time/iter: 715.40 s, time: 347.19 min, \n",
            "Train|| iter: 38 , loss: 0.0366 , nfe: 96.724 , time/iter: 726.72 s, time: 359.30 min, \n",
            "Test || iter: 38 , loss: 5.1099 , acc: 0.5715 , nfe: 32.0 , param cnt: 172452 , \n",
            "Train|| iter: 39 , loss: 0.0339 , nfe: 96.540 , time/iter: 725.80 s, time: 371.70 min, \n",
            "Train|| iter: 40 , loss: 0.0340 , nfe: 98.438 , time/iter: 743.87 s, time: 384.10 min, \n",
            "Test || iter: 40 , loss: 5.4001 , acc: 0.5708 , nfe: 32.0 , param cnt: 172452 , \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}